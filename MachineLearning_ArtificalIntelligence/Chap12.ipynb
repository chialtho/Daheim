{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 12: Time Series Models\n",
    "\n",
    "## 12.1: Introduction\n",
    "\n",
    "- so far only static data, the measurements do not change over time\n",
    "- possible to transform non-static data into static data (to some extent) \n",
    "  $\\Rightarrow$ seldom optimal\n",
    "\n",
    "\n",
    "## 12.2 Stationarity\n",
    "\n",
    "- no change over time\n",
    "- unconditional koint probability ditribtuion of its parameters does not change over time\n",
    "  $\\Rightarrow$ **strict stationarity**\n",
    "- more practical definition: mean and variance does not change over time\n",
    "- weak stationarity: only mean is constant over time\n",
    "  $\\Rightarrow$ weak stationarity, wide sense stationarity\n",
    "- most processes encountered in real life are non-stationarity, but are modelled as stationary processes\n",
    "\n",
    "\n",
    "## 12.3 Autoregressive Moving Average Models\n",
    "\n",
    "- short: ARMA analysis\n",
    "- simple technique of univariate time series analysis\n",
    "- based on two separate concepts: *autoregression* and *moving average*\n",
    "- Define a system: \n",
    "  * discrete time system \n",
    "  * white noise inputs denoted as $\\epsilon_i , i = 1,...,n$\n",
    "  * $i$ denotes the instance of time\n",
    "  * output of the system be denoted as $x_i, i = 1,...,n$\n",
    "  * assume all these variables as univariate and numerical\n",
    "\n",
    "\n",
    "## 12.3.1 Autoregressive process\n",
    "\n",
    "\n",
    "An autoregressive or AR process is a process in which the current output of the system is a function of the weighted sum of a certain number of previous inputs.\n",
    "The AR process is not necessarily stationary.\n",
    "\n",
    "AR process of order p, $AR(p)$\n",
    "\n",
    "\\begin{equation}\n",
    "x_i = \\sum_{j = i - p}^{i - 1} \\alpha_j x_j + \\epsilon_i\n",
    "\\end{equation}\n",
    "\n",
    "with\n",
    "\n",
    "- $\\epsilon_i$: error/residual term at instance $i$\n",
    "- $x_i$: output of system\n",
    "- $\\alpha_i$ coefficients/parameters of the AR process\n",
    "\n",
    "Time lag operator L:\n",
    "\n",
    "$L x_i = x_{i-1} \\forall i$\n",
    "\n",
    "For the *k*th order lag\n",
    "\n",
    "$L^k x_i = x_{i-k} \\forall i$\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "(1 - \\sum_{j=1}^{p} \\alpha_j L^j)\\,\\,x_i = \\epsilon_i\n",
    "\\end{equation}\n",
    "\n",
    "### 12.3.2 Moving Average Process\n",
    "\n",
    "- always stationary\n",
    "- current output is moving average of a certain number of past states of the dault white noise process\n",
    "\n",
    "Moving avergae process of order *q*:\n",
    "\n",
    "\\begin{equation}\n",
    "x_i = \\epsilon_i + \\beta_1 \\epsilon_{i-1} + ... + \\beta_q \\epsilon_{i-q}\n",
    "\\end{equation}\n",
    "\n",
    "- $\\beta_i$ coefficients/parameters of the MA process\n",
    "\n",
    "\n",
    "### 12.3.3 Autoregressive oving Average Process\n",
    "\n",
    "\\begin{equation}\n",
    "x_i = \\alpha_1 x_{i-1} + ... + \\alpha_p x_{i-p} \\epsilon_i + \\beta_1 \\epsilon_{i-1} + ... + \\beta_q \\epsilon_{i-q}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "## 12.4 Autoregressive Integrated Moving Average (ARIMA) Models\n",
    "\n",
    "Although ARMA(p, q) process in general can be non-stationary, it cannot explicitly model a non-stationary process well. s.\n",
    "$\\Rightarrow$ ARIMA, adds differencing terms to the equation\n",
    "THe differencing process explicity tires to remove the trends or seasonalities from the data to make the residual process stationary. \n",
    "\n",
    "Differencing operationas the name suggests computes the deltas between consective values of the output as\n",
    "\n",
    "\\begin{equation}\n",
    "x_d(i) = x(i) - x(i-1)\n",
    "\\end{equation}\n",
    "\n",
    "Here the first-order differences is shown.\n",
    "\n",
    "Here generalized into any arbitrary order $r$ as\n",
    "\n",
    "\\begin{equation}\n",
    "{x_d(i)}^r = {(1 - L)}^r x_i\n",
    "\\end{equation}\n",
    "\n",
    "Full equation of a ARIMA process ARIMA(p, q, r):\n",
    "\n",
    "\\begin{equation}\n",
    "\\left(1 - \\sum_{j=1}^p \\alpha_j L^j \\right) {(1-L)}^r x_i = \\left(1 + \\sum_{j=1}^1 \\beta_j L^j \\right) \\epsilon_i\n",
    "\\end{equation}\n",
    "\n",
    "When the value of $r$ is 0, the ARIMA process reduces to ARMA process.\n",
    "Similarly, when $r$ and $q$ are 0, the ARIMA process reduces to AR process, and when $r$ and $p$ are 0,it reduces to MA process.\n",
    "\n",
    "\n",
    "## 12.5 Implementing AR, MA, ARMA and ARIMA in Python\n",
    "\n",
    "- sklearn does not offer tools directly\n",
    "- other libraries: Darts, Prophet\n",
    "\n",
    "\n",
    "## 12.6 Hidden Markov Models (HMMs)\n",
    "\n",
    "## 12.7 Conditional Random Fields (CRFs)\n",
    "\n",
    "CRFs directly try to model the conditional probabilities of the observations based on the assumptions of similar hidden states. The fundamental function for CRF can be stated as\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y} = arg max\\,y P(y| X)\n",
    "\\end{equation}\n",
    "\n",
    "In order to model the sequential input and states, CRF introduces feature functions. The feature function is defined based on four entities.\n",
    "\n",
    "1. Input vectors **X**\n",
    "1. Instane *i* of the data pont being predicted\n",
    "1. Label for data point at (i - 1)th instance, $l_{i-1}$\n",
    "1. Label for data point at (*i*)th instance $l_i$\n",
    "\n",
    "The function is then given as \n",
    "\n",
    "\\begin{equation}\n",
    "f(X, i, l_{i-1}, l_i)\n",
    "\\end{equation}\n",
    "\n",
    "Using this feature function, the conditional probability is written as \n",
    "\n",
    "\\begin{equation}\n",
    "P(y|X, \\lambda) = \\frac{1}{Z(X)} exp\\left(\\sum_{i=1}^n \\sum_j \\lambda_j f_i(X, i, y_{i-1}, y_i) \\right)\n",
    "\\end{equation}\n",
    "\n",
    "where the normalization constant Z(X) is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "Z(X) = \\sum_{\\hat{y} \\in y} \\sum_{i=1}^n \\sum_j \\lambda_j f_i(X, i, \\hat{y_{i-1}}, \\hat{y_i}) \n",
    "\\end{equation}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
