{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb464b0b",
   "metadata": {},
   "source": [
    "# Chapter 13: Deep Learning\n",
    "\n",
    "## 13.1 Introduction\n",
    "\n",
    "## 13.2 Why Deep Neural Networks?\n",
    "\n",
    "## 13.3 Types of Deep Neural Networks\n",
    "\n",
    "1. Convolutional Neural Networks (CNNs)\n",
    "1. Recurrent Neural Networks (RNNs)\n",
    "1. Generative Adversarial Networks (GANs)\n",
    "1. Attention-based Networks\n",
    "\n",
    "\n",
    "## 13.4 Convolutional Neural Networks (CNNs)\n",
    "\n",
    "- based on convolution operation (signal processing)\n",
    "- can be operated in single or multiple dimensions\n",
    "\n",
    "### 13.4.1 One-Dimensional Convolution\n",
    "\n",
    "- one real valued function operates on another real valued function to produce a new real valued function\n",
    "- continuous convolution:\n",
    "    - for two functions \\(f(t)\\) and \\(g(t)\\), the continuous convolution is defined as:\n",
    "    \\begin{equation}\n",
    "    f(t) * g(t) = (f * g)(t) = \\int_{-\\infty}^{\\infty} f(\\tau) \\cdot g(t - \\tau) \\, d\\tau\n",
    "    \\end{equation}\n",
    "    - convolution is commutative: $f(t) * g(t) = g(t) * f(t)$\n",
    "    - *t* denotes continuous time\n",
    "- discrete convolution:\n",
    "    - for two sequences \\(f[k]\\) and \\(g[k]\\), the discrete convolution is defined as:\n",
    "    \\begin{equation}\n",
    "    (f * g)[k] = \\sum_{\\delta=-\\infty}^{\\infty} f[\\delta] \\cdot g[n - \\delta]\n",
    "    \\end{equation}\n",
    "    - *k* denotes discrete time or index\n",
    "\n",
    "- typically used on speech applications\n",
    "\n",
    "### 13.4.2 Two-Dimensional Convolution\n",
    "\n",
    "- used in image processing\n",
    "- two images A and B, the convolution is defined as:\n",
    "\\begin{equation}\n",
    "(A * B)[i, j] = \\sum_{m=-\\infty}^{\\infty} \\sum_{n=-\\infty}^{\\infty} A[m, n] \\cdot B[i - m, j - n]\n",
    "\\end{equation}\n",
    "\n",
    "- typically the second image is a small matrix called a kernel or filter\n",
    "\n",
    "### 13.4.3 Architecture of CNNs\n",
    "\n",
    "- three units:\n",
    "    1. **Convolutional Layer**: series of 2D kernels, each applied to original image, generating 3D output (feature map)\n",
    "    1. **Rectified Linear Unit (ReLU) Layer**: rectify output of convolutional layer (introduce non-linearity, $f(x) = max(0, x)$), can use signmoid or tanh functions but ReLU is preferred\n",
    "    1. **Pooling Layer**: downsampling by replacing largers sized blocks with single value (e.g., max pooling, average pooling)\n",
    "\n",
    "- Output - fully connected layer: bring information together, often softmax activation for classification\n",
    "\\begin{equation}\n",
    "\\sigma(z)_i = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}} \\quad \\text{for } i = 1, \\ldots, K\n",
    "\\end{equation}\n",
    "- with vector \\(z\\) of length \\(K\\) (dimensions)\n",
    "- softmax normalizes output to sum to 1, can be interpreted as probabilities\n",
    "\n",
    "\n",
    "### 13.4.4 Training CNNs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f4d04",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ee907cb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccdc38f8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
